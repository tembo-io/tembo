services:
  postgres:
    restart: always
    image: quay.io/tembo/timeseries-pg:latest
    ports:
      - 5432:5432
    environment:
      - POSTGRES_PASSWORD=postgres
  gateway:
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      - RUST_LOG=info
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/postgres
      - LLM_SERVICE_HOST_PORT=${LLM_SERVICE_HOST_PORT}
    ports:
      - 8080:8080
  vllm:
    build:
      context: .
      dockerfile: docker/inference/Dockerfile
    command: --model meta-llama/Meta-Llama-3-8B-Instruct --max-model-len 8192
    runtime: nvidia
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    ports:
      - 8000:8000
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
  vllm-cpu:
    build:
      context: .
      dockerfile: docker/inference/Dockerfile.cpu
    ports:
      - 8000:8000
  mock-server:
    build:
      context: .
      dockerfile: docker/inference/Dockerfile.mock
    ports:
      - 8000:8000
