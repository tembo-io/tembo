# Values file for the tembo-ai chart with inference gateway component.

inferenceGateway:
  image:
    repository: quay.io/tembo/inference-gateway
    pullPolicy: IfNotPresent
    tag: latest
  serviceAccount:
    create: true
    annotations: {}
  service:
    port: 8080
  resources:
    requests:
      cpu: 100m
      memory: 410Mi
    limits:
      cpu: 1000m
      memory: 512Mi
  autoscaling:
    enabled: true
    minReplicas: 1
    maxReplicas: 5
    # target CPU is a percentage of requests, i.e. the measurement can
    # exceed 100% when limits is greater than requests.
    targetCPUUtilizationPercentage: 99
  podMonitor:
    enabled: false
    path: /metrics
    # Sometimes applications serve metrics on a different port,
    # which makes it easier to prevent metrics from accidentally
    # being publicly available.
    portName: metrics
    containerPort: 8081
  securityContext:
    # The most practical security settings are
    # dropping all linux capabilities and
    # running as non-root.
    capabilities:
      drop:
      - ALL
    runAsNonRoot: true
    # Read only file system is better if the application
    # can tolerate it.
    # readOnlyRootFilesystem: true
  nodeSelector: {}
  tolerations: []
  affinity: {}
  podAnnotations: {}
  podSecurityContext: {}
